{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zHv-QsKzK4W8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "713c6de7-b00e-4911-d951-8b719b20f962"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "THE BOY WHO LIVED Mr and Mrs Dursley of number four Privet Drive were proud to say that they were perfectly normal thank you very much .They were the last people youd expect to be involved in anything strange or mysterious because they just didnt hold with such nonsense .Mr Dursley was the director of a firm called Grunnings which made drills .He was a big beefy man with hardly any neck although he did have a very large mustache .Mrs Dursley was thin and blonde and had nearly twice the usual amo\n"
          ]
        }
      ],
      "source": [
        "file_path = \"/content/Harry_Potter_all_books_preprocessed.txt\"\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    hp_text = file.read()\n",
        "\n",
        "# Print the first 500 characters to verify the content\n",
        "print(oz_text[:500])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow.keras.utils as keras_utils\n",
        "\n",
        "# Assuming oz_text contains your text data\n",
        "sentences = hp_text.split('. ')\n",
        "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "\n",
        "# Create input sequences and labels\n",
        "input_sequences = []\n",
        "for sequence in sequences:\n",
        "    for i in range(1, len(sequence)):\n",
        "        n_gram_sequence = sequence[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n"
      ],
      "metadata": {
        "id": "guHVCnjUwUQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad sequences\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# Create predictors and labels\n",
        "train_sequences, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "vocab_size = len(tokenizer.word_index) + 1  # Adjusting vocab_size here to ensure it's defined before use\n",
        "labels = keras_utils.to_categorical(labels, num_classes=vocab_size)\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "train_sequences, test_sequences, train_labels, test_labels = train_test_split(train_sequences, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "ydEELpUpHH2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1  # Plus 1 for padding token\n",
        "embed_dim = 64  # Size of the embedding vector\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, embed_dim, input_length=max_sequence_len-1),\n",
        "    LSTM(64),\n",
        "    Dense(vocab_size, activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "id": "pFYrOQiawk3y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Adjust this based on your data preparation step\n",
        "model.fit(train_sequences, train_labels, epochs=100, validation_data=(test_sequences, test_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOhKrFspwl8Y",
        "outputId": "95f6f2d9-5ea0-4c2a-f21c-cd074e32a74c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1040/1040 [==============================] - 45s 41ms/step - loss: 4.7188 - accuracy: 0.1868 - val_loss: 5.9335 - val_accuracy: 0.1326\n",
            "Epoch 2/100\n",
            "1040/1040 [==============================] - 19s 18ms/step - loss: 4.4904 - accuracy: 0.1957 - val_loss: 6.0655 - val_accuracy: 0.1350\n",
            "Epoch 3/100\n",
            "1040/1040 [==============================] - 17s 16ms/step - loss: 4.3326 - accuracy: 0.2042 - val_loss: 6.1515 - val_accuracy: 0.1366\n",
            "Epoch 4/100\n",
            "1040/1040 [==============================] - 16s 16ms/step - loss: 4.1818 - accuracy: 0.2169 - val_loss: 6.2254 - val_accuracy: 0.1385\n",
            "Epoch 5/100\n",
            "1040/1040 [==============================] - 15s 14ms/step - loss: 4.0394 - accuracy: 0.2265 - val_loss: 6.3221 - val_accuracy: 0.1388\n",
            "Epoch 6/100\n",
            "1040/1040 [==============================] - 16s 15ms/step - loss: 3.9047 - accuracy: 0.2363 - val_loss: 6.4238 - val_accuracy: 0.1378\n",
            "Epoch 7/100\n",
            "1040/1040 [==============================] - 15s 14ms/step - loss: 3.7763 - accuracy: 0.2494 - val_loss: 6.5250 - val_accuracy: 0.1359\n",
            "Epoch 8/100\n",
            "1040/1040 [==============================] - 15s 14ms/step - loss: 3.6543 - accuracy: 0.2622 - val_loss: 6.6142 - val_accuracy: 0.1353\n",
            "Epoch 9/100\n",
            "1040/1040 [==============================] - 16s 15ms/step - loss: 3.5363 - accuracy: 0.2774 - val_loss: 6.7126 - val_accuracy: 0.1322\n",
            "Epoch 10/100\n",
            "1040/1040 [==============================] - 15s 14ms/step - loss: 3.4226 - accuracy: 0.2932 - val_loss: 6.8004 - val_accuracy: 0.1319\n",
            "Epoch 11/100\n",
            "1040/1040 [==============================] - 15s 15ms/step - loss: 3.3148 - accuracy: 0.3101 - val_loss: 6.9030 - val_accuracy: 0.1325\n",
            "Epoch 12/100\n",
            "1040/1040 [==============================] - 15s 14ms/step - loss: 3.2102 - accuracy: 0.3262 - val_loss: 6.9879 - val_accuracy: 0.1328\n",
            "Epoch 13/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 3.1110 - accuracy: 0.3429 - val_loss: 7.0770 - val_accuracy: 0.1243\n",
            "Epoch 14/100\n",
            "1040/1040 [==============================] - 16s 15ms/step - loss: 3.0157 - accuracy: 0.3601 - val_loss: 7.1713 - val_accuracy: 0.1240\n",
            "Epoch 15/100\n",
            "1040/1040 [==============================] - 15s 15ms/step - loss: 2.9239 - accuracy: 0.3767 - val_loss: 7.2395 - val_accuracy: 0.1243\n",
            "Epoch 16/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 2.8385 - accuracy: 0.3940 - val_loss: 7.3338 - val_accuracy: 0.1245\n",
            "Epoch 17/100\n",
            "1040/1040 [==============================] - 16s 15ms/step - loss: 2.7540 - accuracy: 0.4096 - val_loss: 7.4220 - val_accuracy: 0.1213\n",
            "Epoch 18/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 2.6760 - accuracy: 0.4249 - val_loss: 7.5027 - val_accuracy: 0.1219\n",
            "Epoch 19/100\n",
            "1040/1040 [==============================] - 15s 14ms/step - loss: 2.6001 - accuracy: 0.4401 - val_loss: 7.5832 - val_accuracy: 0.1198\n",
            "Epoch 20/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 2.5269 - accuracy: 0.4548 - val_loss: 7.6658 - val_accuracy: 0.1207\n",
            "Epoch 21/100\n",
            "1040/1040 [==============================] - 15s 14ms/step - loss: 2.4572 - accuracy: 0.4679 - val_loss: 7.7432 - val_accuracy: 0.1175\n",
            "Epoch 22/100\n",
            "1040/1040 [==============================] - 15s 15ms/step - loss: 2.3908 - accuracy: 0.4811 - val_loss: 7.8223 - val_accuracy: 0.1177\n",
            "Epoch 23/100\n",
            "1040/1040 [==============================] - 15s 14ms/step - loss: 2.3252 - accuracy: 0.4953 - val_loss: 7.9136 - val_accuracy: 0.1162\n",
            "Epoch 24/100\n",
            "1040/1040 [==============================] - 14s 13ms/step - loss: 2.2639 - accuracy: 0.5077 - val_loss: 7.9937 - val_accuracy: 0.1162\n",
            "Epoch 25/100\n",
            "1040/1040 [==============================] - 15s 14ms/step - loss: 2.2041 - accuracy: 0.5191 - val_loss: 8.0431 - val_accuracy: 0.1172\n",
            "Epoch 26/100\n",
            "1040/1040 [==============================] - 14s 13ms/step - loss: 2.1457 - accuracy: 0.5313 - val_loss: 8.1462 - val_accuracy: 0.1170\n",
            "Epoch 27/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 2.0895 - accuracy: 0.5434 - val_loss: 8.2283 - val_accuracy: 0.1132\n",
            "Epoch 28/100\n",
            "1040/1040 [==============================] - 15s 14ms/step - loss: 2.0369 - accuracy: 0.5526 - val_loss: 8.2945 - val_accuracy: 0.1127\n",
            "Epoch 29/100\n",
            "1040/1040 [==============================] - 15s 14ms/step - loss: 1.9829 - accuracy: 0.5659 - val_loss: 8.3721 - val_accuracy: 0.1110\n",
            "Epoch 30/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 1.9330 - accuracy: 0.5775 - val_loss: 8.4317 - val_accuracy: 0.1117\n",
            "Epoch 31/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 1.8838 - accuracy: 0.5844 - val_loss: 8.5195 - val_accuracy: 0.1086\n",
            "Epoch 32/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 1.8362 - accuracy: 0.5957 - val_loss: 8.5979 - val_accuracy: 0.1069\n",
            "Epoch 33/100\n",
            "1040/1040 [==============================] - 15s 14ms/step - loss: 1.7908 - accuracy: 0.6043 - val_loss: 8.6619 - val_accuracy: 0.1103\n",
            "Epoch 34/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 1.7500 - accuracy: 0.6162 - val_loss: 8.7275 - val_accuracy: 0.1063\n",
            "Epoch 35/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 1.7036 - accuracy: 0.6248 - val_loss: 8.7955 - val_accuracy: 0.1077\n",
            "Epoch 36/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 1.6633 - accuracy: 0.6347 - val_loss: 8.8791 - val_accuracy: 0.1051\n",
            "Epoch 37/100\n",
            "1040/1040 [==============================] - 15s 15ms/step - loss: 1.6237 - accuracy: 0.6421 - val_loss: 8.9609 - val_accuracy: 0.1068\n",
            "Epoch 38/100\n",
            "1040/1040 [==============================] - 14s 13ms/step - loss: 1.5846 - accuracy: 0.6531 - val_loss: 9.0404 - val_accuracy: 0.1028\n",
            "Epoch 39/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 1.5484 - accuracy: 0.6595 - val_loss: 9.1185 - val_accuracy: 0.1059\n",
            "Epoch 40/100\n",
            "1040/1040 [==============================] - 15s 14ms/step - loss: 1.5101 - accuracy: 0.6666 - val_loss: 9.1749 - val_accuracy: 0.1045\n",
            "Epoch 41/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 1.4756 - accuracy: 0.6743 - val_loss: 9.2497 - val_accuracy: 0.1034\n",
            "Epoch 42/100\n",
            "1040/1040 [==============================] - 15s 14ms/step - loss: 1.4413 - accuracy: 0.6824 - val_loss: 9.3285 - val_accuracy: 0.1029\n",
            "Epoch 43/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 1.4088 - accuracy: 0.6890 - val_loss: 9.4215 - val_accuracy: 0.1022\n",
            "Epoch 44/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 1.3754 - accuracy: 0.6976 - val_loss: 9.4826 - val_accuracy: 0.1005\n",
            "Epoch 45/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 1.3441 - accuracy: 0.7034 - val_loss: 9.5498 - val_accuracy: 0.1025\n",
            "Epoch 46/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 1.3136 - accuracy: 0.7125 - val_loss: 9.6239 - val_accuracy: 0.1010\n",
            "Epoch 47/100\n",
            "1040/1040 [==============================] - 15s 14ms/step - loss: 1.2846 - accuracy: 0.7184 - val_loss: 9.6791 - val_accuracy: 0.1022\n",
            "Epoch 48/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 1.2566 - accuracy: 0.7226 - val_loss: 9.7626 - val_accuracy: 0.0998\n",
            "Epoch 49/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 1.2277 - accuracy: 0.7279 - val_loss: 9.8337 - val_accuracy: 0.0982\n",
            "Epoch 50/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 1.2017 - accuracy: 0.7365 - val_loss: 9.8986 - val_accuracy: 0.0993\n",
            "Epoch 51/100\n",
            "1040/1040 [==============================] - 15s 15ms/step - loss: 1.1780 - accuracy: 0.7432 - val_loss: 9.9809 - val_accuracy: 0.0996\n",
            "Epoch 52/100\n",
            "1040/1040 [==============================] - 15s 15ms/step - loss: 1.1500 - accuracy: 0.7463 - val_loss: 10.0618 - val_accuracy: 0.0972\n",
            "Epoch 53/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 1.1258 - accuracy: 0.7550 - val_loss: 10.1089 - val_accuracy: 0.1000\n",
            "Epoch 54/100\n",
            "1040/1040 [==============================] - 15s 15ms/step - loss: 1.1042 - accuracy: 0.7580 - val_loss: 10.1876 - val_accuracy: 0.0984\n",
            "Epoch 55/100\n",
            "1040/1040 [==============================] - 15s 15ms/step - loss: 1.0758 - accuracy: 0.7660 - val_loss: 10.2445 - val_accuracy: 0.0966\n",
            "Epoch 56/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 1.0576 - accuracy: 0.7683 - val_loss: 10.3276 - val_accuracy: 0.0999\n",
            "Epoch 57/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 1.0324 - accuracy: 0.7755 - val_loss: 10.4035 - val_accuracy: 0.0998\n",
            "Epoch 58/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 1.0129 - accuracy: 0.7815 - val_loss: 10.4632 - val_accuracy: 0.0998\n",
            "Epoch 59/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 0.9923 - accuracy: 0.7842 - val_loss: 10.5539 - val_accuracy: 0.0961\n",
            "Epoch 60/100\n",
            "1040/1040 [==============================] - 16s 15ms/step - loss: 0.9699 - accuracy: 0.7909 - val_loss: 10.6180 - val_accuracy: 0.0980\n",
            "Epoch 61/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 0.9514 - accuracy: 0.7933 - val_loss: 10.6899 - val_accuracy: 0.0944\n",
            "Epoch 62/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 0.9333 - accuracy: 0.7978 - val_loss: 10.7422 - val_accuracy: 0.0950\n",
            "Epoch 63/100\n",
            "1040/1040 [==============================] - 14s 13ms/step - loss: 0.9152 - accuracy: 0.8026 - val_loss: 10.8280 - val_accuracy: 0.0937\n",
            "Epoch 64/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 0.8971 - accuracy: 0.8074 - val_loss: 10.8771 - val_accuracy: 0.0951\n",
            "Epoch 65/100\n",
            "1040/1040 [==============================] - 15s 14ms/step - loss: 0.8770 - accuracy: 0.8128 - val_loss: 10.9319 - val_accuracy: 0.0955\n",
            "Epoch 66/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 0.8645 - accuracy: 0.8155 - val_loss: 11.0102 - val_accuracy: 0.0925\n",
            "Epoch 67/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 0.8433 - accuracy: 0.8195 - val_loss: 11.0637 - val_accuracy: 0.0951\n",
            "Epoch 68/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 0.8245 - accuracy: 0.8233 - val_loss: 11.1278 - val_accuracy: 0.0950\n",
            "Epoch 69/100\n",
            "1040/1040 [==============================] - 15s 15ms/step - loss: 0.8081 - accuracy: 0.8292 - val_loss: 11.1893 - val_accuracy: 0.0943\n",
            "Epoch 70/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 0.8002 - accuracy: 0.8312 - val_loss: 11.2687 - val_accuracy: 0.0940\n",
            "Epoch 71/100\n",
            "1040/1040 [==============================] - 15s 15ms/step - loss: 0.7806 - accuracy: 0.8355 - val_loss: 11.3293 - val_accuracy: 0.0916\n",
            "Epoch 72/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 0.7672 - accuracy: 0.8359 - val_loss: 11.3877 - val_accuracy: 0.0908\n",
            "Epoch 73/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 0.7531 - accuracy: 0.8401 - val_loss: 11.4720 - val_accuracy: 0.0921\n",
            "Epoch 74/100\n",
            "1040/1040 [==============================] - 16s 15ms/step - loss: 0.7352 - accuracy: 0.8453 - val_loss: 11.5120 - val_accuracy: 0.0918\n",
            "Epoch 75/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 0.7249 - accuracy: 0.8479 - val_loss: 11.5767 - val_accuracy: 0.0939\n",
            "Epoch 76/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 0.7110 - accuracy: 0.8512 - val_loss: 11.6455 - val_accuracy: 0.0922\n",
            "Epoch 77/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 0.6957 - accuracy: 0.8542 - val_loss: 11.7407 - val_accuracy: 0.0943\n",
            "Epoch 78/100\n",
            "1040/1040 [==============================] - 15s 14ms/step - loss: 0.6873 - accuracy: 0.8558 - val_loss: 11.7612 - val_accuracy: 0.0937\n",
            "Epoch 79/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 0.6717 - accuracy: 0.8593 - val_loss: 11.8222 - val_accuracy: 0.0899\n",
            "Epoch 80/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 0.6597 - accuracy: 0.8632 - val_loss: 11.8992 - val_accuracy: 0.0897\n",
            "Epoch 81/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 0.6460 - accuracy: 0.8666 - val_loss: 11.9981 - val_accuracy: 0.0916\n",
            "Epoch 82/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 0.6436 - accuracy: 0.8669 - val_loss: 12.0158 - val_accuracy: 0.0898\n",
            "Epoch 83/100\n",
            "1040/1040 [==============================] - 15s 15ms/step - loss: 0.6265 - accuracy: 0.8704 - val_loss: 12.0949 - val_accuracy: 0.0920\n",
            "Epoch 84/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 0.6158 - accuracy: 0.8726 - val_loss: 12.1324 - val_accuracy: 0.0899\n",
            "Epoch 85/100\n",
            "1040/1040 [==============================] - 15s 14ms/step - loss: 0.6107 - accuracy: 0.8726 - val_loss: 12.2077 - val_accuracy: 0.0883\n",
            "Epoch 86/100\n",
            "1040/1040 [==============================] - 15s 14ms/step - loss: 0.5955 - accuracy: 0.8781 - val_loss: 12.2590 - val_accuracy: 0.0892\n",
            "Epoch 87/100\n",
            "1040/1040 [==============================] - 15s 14ms/step - loss: 0.5853 - accuracy: 0.8784 - val_loss: 12.3527 - val_accuracy: 0.0873\n",
            "Epoch 88/100\n",
            "1040/1040 [==============================] - 15s 15ms/step - loss: 0.5792 - accuracy: 0.8802 - val_loss: 12.3902 - val_accuracy: 0.0905\n",
            "Epoch 89/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 0.5675 - accuracy: 0.8843 - val_loss: 12.4451 - val_accuracy: 0.0893\n",
            "Epoch 90/100\n",
            "1040/1040 [==============================] - 15s 15ms/step - loss: 0.5662 - accuracy: 0.8844 - val_loss: 12.5205 - val_accuracy: 0.0902\n",
            "Epoch 91/100\n",
            "1040/1040 [==============================] - 15s 14ms/step - loss: 0.5496 - accuracy: 0.8887 - val_loss: 12.5602 - val_accuracy: 0.0887\n",
            "Epoch 92/100\n",
            "1040/1040 [==============================] - 15s 14ms/step - loss: 0.5379 - accuracy: 0.8901 - val_loss: 12.6420 - val_accuracy: 0.0883\n",
            "Epoch 93/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 0.5404 - accuracy: 0.8900 - val_loss: 12.6731 - val_accuracy: 0.0885\n",
            "Epoch 94/100\n",
            "1040/1040 [==============================] - 15s 15ms/step - loss: 0.5229 - accuracy: 0.8922 - val_loss: 12.7347 - val_accuracy: 0.0887\n",
            "Epoch 95/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 0.5152 - accuracy: 0.8951 - val_loss: 12.7978 - val_accuracy: 0.0868\n",
            "Epoch 96/100\n",
            "1040/1040 [==============================] - 15s 14ms/step - loss: 0.5048 - accuracy: 0.8979 - val_loss: 12.8570 - val_accuracy: 0.0863\n",
            "Epoch 97/100\n",
            "1040/1040 [==============================] - 14s 14ms/step - loss: 0.4972 - accuracy: 0.9008 - val_loss: 12.9265 - val_accuracy: 0.0848\n",
            "Epoch 98/100\n",
            "1040/1040 [==============================] - 15s 15ms/step - loss: 0.4933 - accuracy: 0.8994 - val_loss: 12.9774 - val_accuracy: 0.0890\n",
            "Epoch 99/100\n",
            "1040/1040 [==============================] - 16s 15ms/step - loss: 0.4900 - accuracy: 0.9009 - val_loss: 13.0287 - val_accuracy: 0.0879\n",
            "Epoch 100/100\n",
            "1040/1040 [==============================] - 15s 14ms/step - loss: 0.4747 - accuracy: 0.9030 - val_loss: 13.0695 - val_accuracy: 0.0863\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7eb47c32f7c0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def generate_text(model, tokenizer, start_seed, num_words, max_sequence_len):\n",
        "    \"\"\"\n",
        "    Generate text using a trained model.\n",
        "\n",
        "    Parameters:\n",
        "        model: Trained Keras model for text generation.\n",
        "        tokenizer: Tokenizer used for the model.\n",
        "        start_seed: Initial seed text to start generation.\n",
        "        num_words: Number of words to generate.\n",
        "        max_sequence_len: The maximum length of sequences used by the model.\n",
        "\n",
        "    Returns:\n",
        "        A string containing the generated text.\n",
        "    \"\"\"\n",
        "    text_generated = start_seed\n",
        "\n",
        "    for _ in range(num_words):\n",
        "        token_list = tokenizer.texts_to_sequences([text_generated])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        predicted = np.argmax(model.predict(token_list, verbose=0), axis=-1)\n",
        "\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        text_generated += \" \" + output_word\n",
        "\n",
        "    return text_generated\n"
      ],
      "metadata": {
        "id": "cq08_UerBQS2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"Dorothy\"\n",
        "next_words = 7  # Number of words to generate\n",
        "\n",
        "# Generate the text\n",
        "generated_text = generate_text(model, tokenizer, seed_text, next_words, max_sequence_len)\n",
        "\n",
        "print(generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLazzHVhBfMy",
        "outputId": "4805dbd0-f02a-45b6-a340-b711bb1f7e0a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dorothy was captured in the same way and\n"
          ]
        }
      ]
    }
  ]
}