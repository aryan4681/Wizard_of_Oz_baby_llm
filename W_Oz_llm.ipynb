{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zHv-QsKzK4W8",
    "outputId": "9fede67c-67c1-41f7-992b-06e9c4254446"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  DOROTHY AND THE WIZARD IN OZ\n",
      "\n",
      "  BY\n",
      "\n",
      "  L. FRANK BAUM\n",
      "\n",
      "  AUTHOR OF THE WIZARD OF OZ, THE LAND OF OZ, OZMA OF OZ, ETC.\n",
      "\n",
      "  ILLUSTRATED BY JOHN R. NEILL\n",
      "\n",
      "  BOOKS OF WONDER WILLIAM MORROW & CO., INC. NEW YORK\n",
      "\n",
      "\n",
      "  [Illustration]\n",
      "\n",
      "\n",
      "  COPYRIGHT 1908 BY L. FRANK BAUM\n",
      "\n",
      "  ALL RIGHTS RESERVED\n",
      "\n",
      "\n",
      "         *       *       *       *       *\n",
      "\n",
      "\n",
      "  [Illustration]\n",
      "\n",
      "\n",
      "  DEDICATED TO HARRIET A. B. NEAL.\n",
      "\n",
      "\n",
      "         *       *       *       *       *\n",
      "\n",
      "\n",
      "To My Readers\n",
      "\n",
      "\n",
      "It's no use; no use at all. The children won't let me\n"
     ]
    }
   ],
   "source": [
    "file_path = \"your path\"\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    oz_text = file.read()\n",
    "\n",
    "# Print the first 500 characters to verify the content\n",
    "print(oz_text[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "guHVCnjUwUQV"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras.utils as keras_utils\n",
    "\n",
    "sentences = oz_text.split('. ')\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "\n",
    "# Create input sequences and labels\n",
    "input_sequences = []\n",
    "for sequence in sequences:\n",
    "    for i in range(1, len(sequence)):\n",
    "        n_gram_sequence = sequence[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ydEELpUpHH2X"
   },
   "outputs": [],
   "source": [
    "# Pad sequences\n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# Create predictors and labels\n",
    "train_sequences, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "vocab_size = len(tokenizer.word_index) + 1  \n",
    "labels = keras_utils.to_categorical(labels, num_classes=vocab_size)\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "train_sequences, test_sequences, train_labels, test_labels = train_test_split(train_sequences, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "pFYrOQiawk3y"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Plus 1 for padding token\n",
    "embed_dim = 64  # Size of the embedding vector\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, embed_dim, input_length=max_sequence_len-1),\n",
    "    LSTM(64),\n",
    "    Dense(vocab_size, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "collapsed": true,
    "id": "cOhKrFspwl8Y",
    "outputId": "84fafc72-e127-4a91-edd5-569c005abc0a"
   },
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Adjust this based on your data preparation step\n",
    "model.fit(train_sequences, train_labels, epochs=30, validation_data=(test_sequences, test_labels))\n"
   ]
  }, "outputs": [],
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "cq08_UerBQS2"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def generate_text(model, tokenizer, start_seed, num_words, max_sequence_len):\n",
    "    \"\"\"\n",
    "    Generate text using a trained model.\n",
    "\n",
    "    Parameters:\n",
    "        model: Trained Keras model for text generation.\n",
    "        tokenizer: Tokenizer used for the model.\n",
    "        start_seed: Initial seed text to start generation.\n",
    "        num_words: Number of words to generate.\n",
    "        max_sequence_len: The maximum length of sequences used by the model.\n",
    "\n",
    "    Returns:\n",
    "        A string containing the generated text.\n",
    "    \"\"\"\n",
    "    text_generated = start_seed\n",
    "\n",
    "    for _ in range(num_words):\n",
    "        token_list = tokenizer.texts_to_sequences([text_generated])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted = np.argmax(model.predict(token_list, verbose=0), axis=-1)\n",
    "\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        text_generated += \" \" + output_word\n",
    "\n",
    "    return text_generated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WLazzHVhBfMy",
    "outputId": "4805dbd0-f02a-45b6-a340-b711bb1f7e0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there is no use to be all right answered the boy\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"there is\"\n",
    "next_words = 9  # Number of words to generate\n",
    "\n",
    "# Generate the text\n",
    "generated_text = generate_text(model, tokenizer, seed_text, next_words, max_sequence_len)\n",
    "\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "8374305265a28bb484d0771d2d4b50a0a68a909ccbf690fea14b4bf24fd61ef3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
